# Multi-Agent Autonomous Research Assistant

## Overview

This repository contains code for a **Multi-Agent Autonomous Research Assistant** that leverages LangGraph and large language models (LLMs) to process research queries. The assistant extracts key topics from a user query, retrieves relevant research documents from both web sources and Arxiv in parallel, summarizes the gathered context, verifies the factual correctness, and finally formats the output into a comprehensive research summary.

## Key Functionalities

- **Query Understanding:**  
  - Extracts the main topic and up to three subtopics from the userâ€™s research query.
  - Uses an LLM to generate a JSON output with keys `"main_topic"` and `"subtopics"`.

- **Parallel Search & Retrieval:**  
  - **Web Search:** Retrieves documents using the `TavilySearchResults` tool.
  - **Arxiv Search:** Retrieves research paper summaries using the `ArxivLoader`.
  - Both searches are executed in parallel for each subtopic and the results are merged into a unified context.

- **Summarization:**  
  - Generates a detailed analysis based on the aggregated search results and the original query.
  - Incorporates feedback from previous summaries and improvement suggestions if available.

- **Fact Verification & Conditional Routing:**  
  - Verifies the factual correctness of the generated summary and outputs JSON indicating whether the summary is verified.
  - A conditional edge routes the workflow back to the summarization node if inaccuracies are detected, allowing for revisions.

- **Formatting & Export:**  
  - Formats the final research summary into Markdown, combining the summary and verification results.
  - The final output is designed to be user-friendly and ready for presentation or further review.

- **Interactive User Interface:**  
  - A Gradio-based interface enables users to submit queries and view the formatted research summary in real time.

## Requirements

- **Python 3.x**
- **Dependencies:**
  - `langgraph`
  - `langchain`
  - `openai`
  - `langchain_groq`
  - `langchain_community`
  - `gradio`
  - Other standard libraries (`json`, `operator`, `typing`, etc.)

- **Environment Variables:**
  - `GROQ_API_KEY`
  - `LANGSMITH_API_KEY`
  - `LANGSMITH_ENDPOINT`
  - `LANGSMITH_TRACING`
  - `LANGSMITH_PROJECT`
  - `TAVILY_API_KEY`

## Usage

1. **Workflow Execution:**  
   Running the main script executes the complete workflow:
   - The workflow diagram is generated and displayed using Mermaid.
   - The final formatted output is rendered in Markdown.
  
2. **Interactive Testing with Gradio:**  
   The Gradio UI allows users to input queries and view the research summary interactively.

## Results Snapshot

Below is a snapshot of the workflow output generated by the assistant:

![Workflow Snapshot](/results/image.png)

## License

This project is licensed under the MIT License.

## Acknowledgments

- Built using **LangGraph** by LangChain Inc.
- Integrates with LLM APIs via **ChatGroq** and community tools.
- UI built using **Gradio**.
